{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing all the ncessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## gettting the dataset\n",
    "df_course = pd.read_csv('online_course_engagement_data.csv', header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>CourseCategory</th>\n",
       "      <th>TimeSpentOnCourse</th>\n",
       "      <th>NumberOfVideosWatched</th>\n",
       "      <th>NumberOfQuizzesTaken</th>\n",
       "      <th>QuizScores</th>\n",
       "      <th>CompletionRate</th>\n",
       "      <th>DeviceType</th>\n",
       "      <th>CourseCompletion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5618</td>\n",
       "      <td>Health</td>\n",
       "      <td>29.979719</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>50.365656</td>\n",
       "      <td>20.860773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4326</td>\n",
       "      <td>Arts</td>\n",
       "      <td>27.802640</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>62.615970</td>\n",
       "      <td>65.632415</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5849</td>\n",
       "      <td>Arts</td>\n",
       "      <td>86.820485</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>78.458962</td>\n",
       "      <td>63.812007</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4992</td>\n",
       "      <td>Science</td>\n",
       "      <td>35.038427</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>59.198853</td>\n",
       "      <td>95.433162</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3866</td>\n",
       "      <td>Programming</td>\n",
       "      <td>92.490647</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>98.428285</td>\n",
       "      <td>18.102478</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID CourseCategory  TimeSpentOnCourse  NumberOfVideosWatched  \\\n",
       "0    5618         Health          29.979719                     17   \n",
       "1    4326           Arts          27.802640                      1   \n",
       "2    5849           Arts          86.820485                     14   \n",
       "3    4992        Science          35.038427                     17   \n",
       "4    3866    Programming          92.490647                     16   \n",
       "\n",
       "   NumberOfQuizzesTaken  QuizScores  CompletionRate  DeviceType  \\\n",
       "0                     3   50.365656       20.860773           1   \n",
       "1                     5   62.615970       65.632415           1   \n",
       "2                     2   78.458962       63.812007           1   \n",
       "3                    10   59.198853       95.433162           0   \n",
       "4                     0   98.428285       18.102478           0   \n",
       "\n",
       "   CourseCompletion  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_course.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for Nan values \n",
    "nanvals = df_course.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different course names\n",
    "course_no = df_course['CourseCategory']\n",
    "courses = df_course['CourseCategory'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0            Health\n",
       " 1              Arts\n",
       " 2              Arts\n",
       " 3           Science\n",
       " 4       Programming\n",
       "            ...     \n",
       " 8995         Health\n",
       " 8996        Science\n",
       " 8997         Health\n",
       " 8998         Health\n",
       " 8999         Health\n",
       " Name: CourseCategory, Length: 9000, dtype: object,\n",
       " array(['Health', 'Arts', 'Science', 'Programming', 'Business'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "course_no, courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1821.,    0., 1718.,    0.,    0., 1814.,    0., 1810.,    0.,\n",
       "        1837.]),\n",
       " array([0. , 0.4, 0.8, 1.2, 1.6, 2. , 2.4, 2.8, 3.2, 3.6, 4. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## plotting as an histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(course_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating a dict to convert course names to course codes\n",
    " \n",
    "c_dict = {\n",
    "    'Health': 1,\n",
    "    'Arts': 2,\n",
    "    'Science': 3,\n",
    "    'Programming':4,\n",
    "    'Business': 5\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## maping the dictionary to the values\n",
    "df_course['Course_id'] = df_course['CourseCategory'].map(c_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>CourseCategory</th>\n",
       "      <th>TimeSpentOnCourse</th>\n",
       "      <th>NumberOfVideosWatched</th>\n",
       "      <th>NumberOfQuizzesTaken</th>\n",
       "      <th>QuizScores</th>\n",
       "      <th>CompletionRate</th>\n",
       "      <th>DeviceType</th>\n",
       "      <th>CourseCompletion</th>\n",
       "      <th>Course_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5618</td>\n",
       "      <td>Health</td>\n",
       "      <td>29.979719</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>50.365656</td>\n",
       "      <td>20.860773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4326</td>\n",
       "      <td>Arts</td>\n",
       "      <td>27.802640</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>62.615970</td>\n",
       "      <td>65.632415</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5849</td>\n",
       "      <td>Arts</td>\n",
       "      <td>86.820485</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>78.458962</td>\n",
       "      <td>63.812007</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4992</td>\n",
       "      <td>Science</td>\n",
       "      <td>35.038427</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>59.198853</td>\n",
       "      <td>95.433162</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3866</td>\n",
       "      <td>Programming</td>\n",
       "      <td>92.490647</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>98.428285</td>\n",
       "      <td>18.102478</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID CourseCategory  TimeSpentOnCourse  NumberOfVideosWatched  \\\n",
       "0    5618         Health          29.979719                     17   \n",
       "1    4326           Arts          27.802640                      1   \n",
       "2    5849           Arts          86.820485                     14   \n",
       "3    4992        Science          35.038427                     17   \n",
       "4    3866    Programming          92.490647                     16   \n",
       "\n",
       "   NumberOfQuizzesTaken  QuizScores  CompletionRate  DeviceType  \\\n",
       "0                     3   50.365656       20.860773           1   \n",
       "1                     5   62.615970       65.632415           1   \n",
       "2                     2   78.458962       63.812007           1   \n",
       "3                    10   59.198853       95.433162           0   \n",
       "4                     0   98.428285       18.102478           0   \n",
       "\n",
       "   CourseCompletion  Course_id  \n",
       "0                 0          1  \n",
       "1                 0          2  \n",
       "2                 1          2  \n",
       "3                 1          3  \n",
       "4                 0          4  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_course[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rearrannging columns\n",
    "col = df_course.pop('Course_id') \n",
    "df_course.insert(2, 'Course_id', col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>CourseCategory</th>\n",
       "      <th>Course_id</th>\n",
       "      <th>TimeSpentOnCourse</th>\n",
       "      <th>NumberOfVideosWatched</th>\n",
       "      <th>NumberOfQuizzesTaken</th>\n",
       "      <th>QuizScores</th>\n",
       "      <th>CompletionRate</th>\n",
       "      <th>DeviceType</th>\n",
       "      <th>CourseCompletion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5618</td>\n",
       "      <td>Health</td>\n",
       "      <td>1</td>\n",
       "      <td>29.979719</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>50.365656</td>\n",
       "      <td>20.860773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4326</td>\n",
       "      <td>Arts</td>\n",
       "      <td>2</td>\n",
       "      <td>27.802640</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>62.615970</td>\n",
       "      <td>65.632415</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5849</td>\n",
       "      <td>Arts</td>\n",
       "      <td>2</td>\n",
       "      <td>86.820485</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>78.458962</td>\n",
       "      <td>63.812007</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4992</td>\n",
       "      <td>Science</td>\n",
       "      <td>3</td>\n",
       "      <td>35.038427</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>59.198853</td>\n",
       "      <td>95.433162</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3866</td>\n",
       "      <td>Programming</td>\n",
       "      <td>4</td>\n",
       "      <td>92.490647</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>98.428285</td>\n",
       "      <td>18.102478</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8995</th>\n",
       "      <td>8757</td>\n",
       "      <td>Health</td>\n",
       "      <td>1</td>\n",
       "      <td>37.445225</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>54.469359</td>\n",
       "      <td>32.990704</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8996</th>\n",
       "      <td>894</td>\n",
       "      <td>Science</td>\n",
       "      <td>3</td>\n",
       "      <td>48.631443</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>59.413257</td>\n",
       "      <td>0.254625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8997</th>\n",
       "      <td>6323</td>\n",
       "      <td>Health</td>\n",
       "      <td>1</td>\n",
       "      <td>38.212512</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>69.508297</td>\n",
       "      <td>70.188159</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8998</th>\n",
       "      <td>3652</td>\n",
       "      <td>Health</td>\n",
       "      <td>1</td>\n",
       "      <td>70.048665</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>79.655182</td>\n",
       "      <td>72.975225</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>5595</td>\n",
       "      <td>Health</td>\n",
       "      <td>1</td>\n",
       "      <td>93.589781</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>56.274546</td>\n",
       "      <td>11.299071</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      UserID CourseCategory  Course_id  TimeSpentOnCourse  \\\n",
       "0       5618         Health          1          29.979719   \n",
       "1       4326           Arts          2          27.802640   \n",
       "2       5849           Arts          2          86.820485   \n",
       "3       4992        Science          3          35.038427   \n",
       "4       3866    Programming          4          92.490647   \n",
       "...      ...            ...        ...                ...   \n",
       "8995    8757         Health          1          37.445225   \n",
       "8996     894        Science          3          48.631443   \n",
       "8997    6323         Health          1          38.212512   \n",
       "8998    3652         Health          1          70.048665   \n",
       "8999    5595         Health          1          93.589781   \n",
       "\n",
       "      NumberOfVideosWatched  NumberOfQuizzesTaken  QuizScores  CompletionRate  \\\n",
       "0                        17                     3   50.365656       20.860773   \n",
       "1                         1                     5   62.615970       65.632415   \n",
       "2                        14                     2   78.458962       63.812007   \n",
       "3                        17                    10   59.198853       95.433162   \n",
       "4                        16                     0   98.428285       18.102478   \n",
       "...                     ...                   ...         ...             ...   \n",
       "8995                     14                     4   54.469359       32.990704   \n",
       "8996                      7                     7   59.413257        0.254625   \n",
       "8997                      3                     3   69.508297       70.188159   \n",
       "8998                     13                    10   79.655182       72.975225   \n",
       "8999                      7                     5   56.274546       11.299071   \n",
       "\n",
       "      DeviceType  CourseCompletion  \n",
       "0              1                 0  \n",
       "1              1                 0  \n",
       "2              1                 1  \n",
       "3              0                 1  \n",
       "4              0                 0  \n",
       "...          ...               ...  \n",
       "8995           1                 0  \n",
       "8996           0                 0  \n",
       "8997           1                 0  \n",
       "8998           1                 1  \n",
       "8999           0                 0  \n",
       "\n",
       "[9000 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the x and y variable\n",
    "\n",
    "X_row = df_course[['Course_id','TimeSpentOnCourse','NumberOfVideosWatched','NumberOfQuizzesTaken','QuizScores','CompletionRate','DeviceType']]\n",
    "\n",
    "y_row = df_course[['CourseCompletion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting them to numpy arrays\n",
    "X_array = X_row.to_numpy()\n",
    "y_array = y_row.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to tensor\n",
    "X_course = torch.from_numpy(X_array).type(torch.float)\n",
    "y_course = torch.from_numpy(y_array).type(torch.float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([9000, 7]), torch.Size([9000, 1]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_course.size(), y_course.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_course_train, X_course_test, y_course_train, y_course_test = train_test_split(X_course,y_course,\n",
    "                                                                                test_size= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7200, 1800, 7200, 1800)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_course_train),len(X_course_test), len(y_course_train), len(y_course_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class CourseComp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(in_features= 7, out_features= 21)\n",
    "        self.layer2 = nn.Linear(in_features= 21, out_features= 21)\n",
    "        self.layer3 = nn.Linear(in_features=21, out_features=21)\n",
    "        self.layer4 = nn.Linear(in_features= 21, out_features=21)\n",
    "        self.layer5 = nn.Linear(in_features= 21, out_features=1)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.layer5(self.relu(self.layer4(self.relu(self.layer3(self.relu(self.layer2(self.relu(self.layer1(x)))))))))\n",
    "\n",
    "model_0 = CourseComp()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layer1.weight',\n",
       "              tensor([[-2.2757e-01, -1.5209e-01,  4.7703e-02, -2.5512e-01, -3.7636e-01,\n",
       "                       -3.6836e-01, -3.2835e-01],\n",
       "                      [ 3.4211e-01,  4.1544e-02,  2.4975e-01,  3.2172e-01,  3.4737e-01,\n",
       "                        4.8252e-02, -2.4604e-01],\n",
       "                      [ 2.7532e-01, -1.2266e-01,  9.3244e-03,  2.3997e-01, -1.4436e-01,\n",
       "                        5.5990e-02, -1.0362e-01],\n",
       "                      [ 5.9656e-02,  2.9270e-01, -3.5962e-02,  1.9832e-01,  1.1663e-01,\n",
       "                       -1.4610e-01, -8.8075e-02],\n",
       "                      [ 3.1271e-01, -1.6324e-01, -9.7296e-02, -7.3685e-02, -3.2474e-01,\n",
       "                        1.5205e-01, -3.5694e-01],\n",
       "                      [-1.7527e-01,  8.2349e-02, -9.8174e-02, -2.4061e-01,  3.5086e-01,\n",
       "                        4.2272e-02,  3.1846e-01],\n",
       "                      [-8.9689e-02,  2.4297e-01,  1.4388e-01, -2.9163e-02, -3.4660e-01,\n",
       "                       -1.8337e-02,  2.2407e-01],\n",
       "                      [ 3.7754e-01,  1.0647e-01, -2.2569e-01,  2.5005e-01,  2.8107e-01,\n",
       "                        4.9543e-02, -3.1553e-01],\n",
       "                      [-9.9531e-02,  1.3923e-01, -8.1690e-02, -1.4851e-01, -4.9146e-02,\n",
       "                       -1.9244e-01,  2.1263e-01],\n",
       "                      [-3.2744e-01,  2.7911e-01, -2.2909e-01, -3.6904e-01,  1.0209e-01,\n",
       "                       -6.6534e-02, -2.5651e-01],\n",
       "                      [ 2.2932e-01,  3.2385e-01, -2.7190e-01, -1.0497e-01,  1.9005e-01,\n",
       "                        7.9026e-02,  3.7046e-01],\n",
       "                      [-2.8794e-01, -2.0428e-01, -3.1125e-01, -2.4040e-03,  2.5509e-01,\n",
       "                       -2.0787e-01, -1.7276e-01],\n",
       "                      [ 3.4943e-01, -1.0800e-01, -3.1005e-01,  8.4998e-02, -1.9816e-01,\n",
       "                       -3.0063e-01,  4.7863e-02],\n",
       "                      [ 2.7060e-01, -1.4354e-01,  2.0214e-01,  3.0225e-02,  1.5553e-01,\n",
       "                       -6.5661e-02, -9.3290e-03],\n",
       "                      [-1.1039e-04,  1.3449e-01,  1.8136e-02,  2.5855e-01,  1.2639e-02,\n",
       "                        3.5912e-02,  6.3336e-02],\n",
       "                      [-1.9591e-01,  4.9269e-02,  1.3298e-01,  2.4873e-01, -8.9887e-02,\n",
       "                       -2.4412e-01,  3.6747e-02],\n",
       "                      [ 6.4413e-02, -3.4600e-01,  1.6098e-01, -3.5644e-01, -1.5073e-01,\n",
       "                       -3.3222e-02, -1.0730e-01],\n",
       "                      [-2.2330e-01,  1.8710e-01, -7.1954e-02,  9.2832e-03, -3.1388e-01,\n",
       "                        2.2822e-03, -1.2355e-01],\n",
       "                      [-3.2245e-01,  1.1329e-01, -3.1896e-01, -3.5393e-01, -9.0139e-02,\n",
       "                       -7.9630e-02,  4.2316e-02],\n",
       "                      [-9.7158e-02,  2.8817e-01, -2.2577e-01, -2.3787e-01, -3.2222e-01,\n",
       "                        3.3714e-01, -9.8491e-02],\n",
       "                      [ 2.5122e-01,  7.9624e-02,  2.3763e-01, -3.9801e-02, -2.7427e-01,\n",
       "                        6.2810e-02,  2.8499e-01]])),\n",
       "             ('layer1.bias',\n",
       "              tensor([-0.1778, -0.2324,  0.0367, -0.1492,  0.0078, -0.2182,  0.0789,  0.2818,\n",
       "                      -0.3561,  0.1421, -0.1923,  0.1796,  0.1697, -0.2248, -0.3573,  0.0027,\n",
       "                      -0.0700, -0.1121, -0.3493, -0.2382, -0.0277])),\n",
       "             ('layer2.weight',\n",
       "              tensor([[ 1.8294e-01,  1.1666e-02,  9.8712e-02,  1.7133e-01,  5.2815e-02,\n",
       "                        9.1499e-02, -1.1998e-01,  1.5721e-01, -1.8856e-01, -1.4233e-01,\n",
       "                        5.2343e-03, -2.0758e-01,  1.9802e-01,  5.0197e-02, -1.9314e-01,\n",
       "                        1.3750e-01,  1.4105e-01,  7.7195e-02,  8.9794e-02,  1.1171e-01,\n",
       "                       -1.3005e-03],\n",
       "                      [ 1.1137e-01, -1.9794e-01, -1.0764e-01, -3.0019e-02, -2.1619e-01,\n",
       "                       -1.8106e-01,  1.2118e-01, -1.3891e-02,  7.3568e-02,  8.3138e-02,\n",
       "                       -2.9131e-02, -1.5430e-01, -1.0720e-01,  9.8866e-02,  1.7716e-01,\n",
       "                        1.7981e-02,  7.6115e-02, -1.4229e-01,  6.3191e-02,  1.5040e-01,\n",
       "                        6.0916e-02],\n",
       "                      [-8.1327e-02,  1.8689e-01, -2.1057e-01, -7.4288e-02, -7.0950e-02,\n",
       "                        1.9149e-01,  9.7556e-02,  1.6524e-01,  6.3229e-02,  1.3561e-01,\n",
       "                        2.1806e-01, -1.6117e-01, -1.6566e-01,  1.9670e-01, -7.6953e-03,\n",
       "                       -1.9730e-01, -1.9799e-01,  6.0040e-02,  1.1420e-01,  1.1730e-01,\n",
       "                        1.9378e-02],\n",
       "                      [ 7.6704e-02,  1.7358e-01, -3.2086e-02,  5.2647e-02,  1.1648e-01,\n",
       "                        4.1422e-02, -9.1777e-02,  1.3073e-01, -1.4130e-01,  1.0010e-01,\n",
       "                        1.8065e-01, -1.7103e-01,  1.3627e-01, -4.0540e-02, -5.7712e-02,\n",
       "                        8.0018e-02, -4.6479e-02,  2.0562e-01, -1.1918e-01,  6.5207e-02,\n",
       "                       -4.4144e-02],\n",
       "                      [-1.8068e-02,  4.2283e-02, -1.9459e-01,  1.0603e-01,  1.1642e-01,\n",
       "                        1.7807e-01, -1.6897e-01,  4.3120e-02, -2.5142e-02,  8.7496e-02,\n",
       "                       -6.1700e-02,  1.1392e-01,  3.0136e-02,  7.8363e-03,  1.2148e-01,\n",
       "                       -1.7263e-01, -1.0137e-01,  1.1893e-01, -4.0300e-02,  1.3319e-01,\n",
       "                        1.0205e-03],\n",
       "                      [-1.4075e-01, -1.4212e-01, -1.7170e-01, -8.0958e-03,  2.1407e-01,\n",
       "                       -1.4795e-01,  1.3707e-01, -1.8029e-01, -9.0967e-02, -1.1540e-01,\n",
       "                       -1.0817e-01, -1.9901e-01, -9.7500e-03, -1.2465e-01, -1.7031e-01,\n",
       "                        1.6611e-01, -9.4562e-02, -1.4195e-01,  8.1574e-02,  2.0953e-01,\n",
       "                        1.0882e-01],\n",
       "                      [-3.8477e-02,  8.3514e-02, -1.7992e-02,  2.0136e-01, -1.4574e-01,\n",
       "                       -1.9151e-02,  4.4445e-02,  5.1549e-03, -1.4326e-01,  2.1109e-01,\n",
       "                       -5.6542e-03, -1.6206e-01,  6.3857e-02, -1.4349e-01, -9.9559e-02,\n",
       "                       -5.6105e-02, -2.5994e-02, -1.5410e-01,  1.6056e-01, -1.6618e-01,\n",
       "                        2.0790e-01],\n",
       "                      [ 2.3039e-02, -2.8668e-02, -1.6355e-01, -1.6533e-01, -1.7534e-02,\n",
       "                       -1.9729e-01, -1.1597e-01,  1.9686e-01,  1.2935e-02,  1.8399e-01,\n",
       "                        1.0937e-01,  1.1054e-01,  5.1738e-02, -1.7842e-01, -1.3994e-01,\n",
       "                        2.3778e-02,  8.9126e-02, -4.2068e-02,  1.0789e-01,  3.5774e-02,\n",
       "                       -2.0863e-01],\n",
       "                      [-1.8731e-01,  1.8437e-01, -3.5330e-02, -6.8772e-02,  1.6556e-01,\n",
       "                        7.5191e-02, -1.8245e-01,  2.0321e-01,  7.6575e-02,  1.5861e-01,\n",
       "                       -4.8609e-03, -1.0985e-01, -1.0625e-01, -1.3169e-01, -1.6375e-01,\n",
       "                        1.6291e-01, -1.6839e-01,  9.7990e-02, -6.5572e-02, -3.1374e-02,\n",
       "                        3.8064e-02],\n",
       "                      [-1.2204e-01,  1.7537e-01,  1.5826e-01,  8.9421e-02, -8.3743e-02,\n",
       "                        1.9403e-01,  4.1209e-02, -2.0185e-01, -4.6142e-02,  2.1571e-01,\n",
       "                       -1.8183e-01,  1.5062e-01,  5.3915e-02,  9.4282e-03,  1.8947e-01,\n",
       "                        1.2060e-01, -1.9777e-01,  1.3211e-02, -2.7241e-02,  1.0097e-01,\n",
       "                       -2.1812e-01],\n",
       "                      [-3.3747e-02, -2.0258e-01, -9.2877e-03,  6.4308e-02, -1.8692e-01,\n",
       "                       -1.9099e-01,  8.7104e-02,  1.7290e-01, -5.2736e-02, -1.6907e-01,\n",
       "                        1.1510e-02,  8.8612e-03, -3.8528e-02, -1.6626e-01, -2.1797e-01,\n",
       "                        1.4854e-01,  1.6086e-01, -8.5513e-02, -1.1484e-01,  1.5990e-01,\n",
       "                        1.5107e-01],\n",
       "                      [ 6.0014e-02,  1.9283e-01, -1.8449e-01, -8.5561e-04,  1.3525e-01,\n",
       "                        5.4329e-02, -1.9487e-01,  4.0091e-02,  1.1761e-04,  1.0651e-02,\n",
       "                        1.7060e-01, -1.8248e-03,  5.0890e-02,  8.2636e-02,  8.3047e-02,\n",
       "                       -8.1613e-02, -1.5602e-01,  7.6307e-02,  1.0403e-02, -1.8068e-01,\n",
       "                       -2.0881e-01],\n",
       "                      [-8.5406e-02,  1.1461e-01, -8.5511e-02,  1.3565e-01, -1.2713e-01,\n",
       "                        1.8816e-01, -1.2889e-01,  1.8273e-01,  1.5669e-01,  2.0568e-01,\n",
       "                        1.5307e-01,  2.9756e-02, -8.8005e-02, -7.8693e-02,  2.1713e-01,\n",
       "                       -1.2957e-01,  1.8854e-01,  1.9700e-01, -1.6501e-01, -1.7730e-01,\n",
       "                        1.5963e-01],\n",
       "                      [-5.0663e-02,  1.6201e-01, -1.2211e-01, -1.7798e-01,  3.1404e-02,\n",
       "                       -1.1989e-01, -8.1805e-02, -1.7612e-02, -3.7927e-02,  2.5839e-02,\n",
       "                       -1.4959e-01,  8.1632e-02,  5.8246e-02,  7.5370e-02,  1.1301e-01,\n",
       "                        3.3196e-02, -6.2849e-02,  2.0367e-01, -2.0574e-01, -3.3327e-02,\n",
       "                       -1.1566e-01],\n",
       "                      [ 9.5077e-02,  6.3303e-02, -1.9032e-01, -1.3610e-02,  5.4215e-02,\n",
       "                       -8.4801e-02, -1.3900e-02, -1.7910e-01, -1.6002e-01,  1.0708e-01,\n",
       "                        2.6540e-02, -1.6094e-01, -4.3575e-02,  1.9119e-02, -1.4665e-01,\n",
       "                       -1.7617e-01,  2.0445e-01, -1.1944e-01,  1.4016e-02, -1.5691e-01,\n",
       "                        1.5626e-03],\n",
       "                      [ 8.7041e-02,  3.9862e-02,  1.6967e-01, -7.6082e-02, -1.3133e-01,\n",
       "                       -1.4465e-02,  1.8780e-01,  1.2971e-01,  2.1105e-02,  1.3387e-01,\n",
       "                       -9.4755e-04, -1.1943e-01, -1.0638e-01,  1.5695e-01,  8.8882e-02,\n",
       "                       -1.1872e-01, -8.6440e-02,  3.4607e-02, -1.7561e-01,  5.5719e-02,\n",
       "                       -6.8405e-02],\n",
       "                      [ 1.3107e-01, -6.4251e-02,  7.4874e-03,  1.6324e-01,  1.9664e-01,\n",
       "                       -7.2125e-02,  2.0951e-01, -1.8347e-01, -1.2064e-02,  1.6422e-01,\n",
       "                       -3.7272e-03,  1.4735e-01,  1.1904e-01, -8.0123e-02,  1.4904e-01,\n",
       "                        1.5534e-01, -1.0620e-01, -3.5097e-02,  8.4423e-02, -1.1016e-01,\n",
       "                        1.8774e-01],\n",
       "                      [ 1.4290e-02,  4.4962e-02, -1.1679e-01,  2.0018e-01, -1.5218e-01,\n",
       "                        1.9212e-01, -9.9981e-03, -1.0390e-01,  6.6158e-02, -1.6440e-01,\n",
       "                        1.4710e-01,  7.7342e-02,  3.9995e-02, -1.2498e-01, -1.6200e-01,\n",
       "                       -1.1109e-01, -1.0214e-02, -7.8568e-02, -9.2731e-02,  1.9028e-01,\n",
       "                        8.3575e-02],\n",
       "                      [ 2.0313e-01, -5.9319e-02,  1.8016e-01, -1.3330e-01, -1.4989e-01,\n",
       "                        1.4926e-01, -6.4274e-02,  7.0782e-02,  3.6669e-02,  2.5359e-02,\n",
       "                       -1.0411e-01, -1.7654e-01,  8.1643e-02, -9.6860e-02,  8.1916e-02,\n",
       "                        3.2845e-02, -7.2995e-02, -9.5121e-03,  5.8927e-02, -1.2630e-01,\n",
       "                        1.4253e-01],\n",
       "                      [-1.2100e-01,  3.0064e-02, -1.2190e-01,  2.1772e-01, -1.6301e-01,\n",
       "                        1.1573e-01, -1.3903e-01, -1.8886e-01,  1.5610e-02, -2.1399e-01,\n",
       "                       -1.5326e-01,  8.9842e-02,  9.3514e-02,  9.3448e-02,  2.1462e-01,\n",
       "                        2.1291e-01,  1.7680e-01, -9.0561e-02, -1.1832e-01, -3.3401e-02,\n",
       "                        1.7523e-01],\n",
       "                      [ 2.5441e-02, -1.7910e-01, -4.8758e-02,  1.7005e-01, -1.6590e-01,\n",
       "                       -1.0818e-01, -1.4428e-01, -6.6845e-02, -7.8807e-02,  1.7293e-01,\n",
       "                       -5.9477e-02,  1.8702e-01, -9.4354e-02,  5.2222e-02,  1.0287e-01,\n",
       "                       -1.3885e-01, -1.5095e-01, -1.8848e-03,  4.8849e-03,  2.5806e-02,\n",
       "                        1.4280e-01]])),\n",
       "             ('layer2.bias',\n",
       "              tensor([-0.1003, -0.0370,  0.0712,  0.2033,  0.1914, -0.2139, -0.0976,  0.0910,\n",
       "                      -0.0911,  0.1585, -0.1385, -0.1042,  0.0903, -0.0816, -0.1690, -0.2098,\n",
       "                       0.2056, -0.1235,  0.1452,  0.2163, -0.1527])),\n",
       "             ('layer3.weight',\n",
       "              tensor([[ 0.2117,  0.0332, -0.1643, -0.1685,  0.1864, -0.1669,  0.0798, -0.1884,\n",
       "                       -0.1817, -0.1436, -0.2055, -0.0962, -0.1946, -0.1413, -0.1372,  0.2122,\n",
       "                        0.1694,  0.1307,  0.1562,  0.0735, -0.0153],\n",
       "                      [ 0.0972, -0.1917, -0.0717,  0.2042, -0.1398,  0.0712,  0.0378, -0.1778,\n",
       "                       -0.1570,  0.0391, -0.1932,  0.2067,  0.2085,  0.1426, -0.0132, -0.0793,\n",
       "                       -0.0212,  0.0919,  0.2083,  0.0246,  0.0489],\n",
       "                      [ 0.0334,  0.1230, -0.1490, -0.0236,  0.0859,  0.1993, -0.2047, -0.1448,\n",
       "                       -0.0256, -0.0079,  0.0727, -0.0493, -0.1233,  0.1451,  0.0436,  0.1945,\n",
       "                       -0.0982,  0.1049,  0.0349, -0.0300,  0.0839],\n",
       "                      [ 0.1595,  0.0344,  0.0611, -0.0893,  0.0192,  0.1361,  0.1894, -0.1681,\n",
       "                        0.0218,  0.0775, -0.0211, -0.0112, -0.1792, -0.1900, -0.0572,  0.0214,\n",
       "                       -0.1623,  0.0547,  0.0783,  0.0516,  0.0510],\n",
       "                      [-0.1252,  0.1133,  0.0591,  0.0997,  0.0706,  0.1357,  0.1207,  0.1090,\n",
       "                        0.0815, -0.2070,  0.1209,  0.1940,  0.1733,  0.0376,  0.1678, -0.1318,\n",
       "                       -0.0879, -0.0830, -0.0682,  0.1404, -0.0857],\n",
       "                      [ 0.0297, -0.1081,  0.0865,  0.1705, -0.0928,  0.1258,  0.1374, -0.0664,\n",
       "                       -0.1177,  0.1383,  0.1409, -0.1575, -0.0587, -0.2130, -0.0451, -0.1114,\n",
       "                        0.1085,  0.1053,  0.1680,  0.1135, -0.2009],\n",
       "                      [ 0.0095, -0.0356,  0.0139,  0.1678, -0.1966,  0.1984, -0.0471, -0.0006,\n",
       "                        0.1804, -0.1540,  0.1674, -0.0283, -0.0615, -0.1381, -0.1270,  0.1633,\n",
       "                        0.0723,  0.0915,  0.0597,  0.2044,  0.0571],\n",
       "                      [ 0.0186,  0.1687,  0.1678,  0.0897, -0.0201,  0.2096,  0.1323, -0.0549,\n",
       "                       -0.1729, -0.1085, -0.2046,  0.1564, -0.0746, -0.1135, -0.1617,  0.1203,\n",
       "                       -0.1282,  0.0782,  0.0775, -0.1086, -0.0770],\n",
       "                      [-0.1808,  0.0253,  0.0147, -0.1133,  0.1027, -0.0696, -0.2179,  0.0148,\n",
       "                       -0.0861, -0.1269,  0.1222,  0.1658,  0.1755,  0.2032,  0.1036, -0.0627,\n",
       "                       -0.1020,  0.1724, -0.0522,  0.1054,  0.1349],\n",
       "                      [-0.1146, -0.1443,  0.1501, -0.0104,  0.1210,  0.0448, -0.1956, -0.0026,\n",
       "                       -0.0207, -0.0901, -0.0466, -0.0828,  0.0730, -0.1377,  0.0635,  0.1913,\n",
       "                        0.1693, -0.1159,  0.1110, -0.0027, -0.1647],\n",
       "                      [-0.0096, -0.1232,  0.0950, -0.1105, -0.0130, -0.0602, -0.2097, -0.1002,\n",
       "                       -0.0363,  0.1980, -0.0174, -0.0775,  0.2175, -0.1771,  0.0133,  0.1097,\n",
       "                       -0.0744, -0.0444,  0.1830,  0.0845,  0.0596],\n",
       "                      [ 0.1484,  0.2092,  0.0026, -0.0946, -0.1407, -0.0742,  0.1086,  0.0664,\n",
       "                       -0.0279,  0.1370, -0.1105, -0.0361, -0.2100, -0.1635, -0.1649,  0.0507,\n",
       "                        0.0345, -0.0116, -0.1936, -0.1886,  0.0406],\n",
       "                      [ 0.1570, -0.0282, -0.0855,  0.1700,  0.0755, -0.1970,  0.0478,  0.1238,\n",
       "                        0.0224,  0.1122,  0.1369, -0.1325,  0.0862, -0.1758,  0.1729, -0.2152,\n",
       "                       -0.0278,  0.0803, -0.0597,  0.2003,  0.0860],\n",
       "                      [-0.0268,  0.0573, -0.2030, -0.0039,  0.1227,  0.1142, -0.0008,  0.0927,\n",
       "                       -0.1775,  0.1463,  0.0665,  0.0128, -0.0096,  0.1937,  0.1001, -0.1302,\n",
       "                        0.1906,  0.0930,  0.0450,  0.0944,  0.0853],\n",
       "                      [-0.0085,  0.1480, -0.0060, -0.0293, -0.0917,  0.1926,  0.0663, -0.0888,\n",
       "                       -0.0098, -0.0145, -0.0613, -0.0927, -0.1566,  0.1300, -0.1823,  0.1467,\n",
       "                        0.1146, -0.1727,  0.1588, -0.2001,  0.2097],\n",
       "                      [-0.1450, -0.1675, -0.1878, -0.0841, -0.1970, -0.0290, -0.0873, -0.1982,\n",
       "                        0.1822, -0.0725,  0.2104,  0.2131, -0.1088, -0.1892,  0.0404,  0.0884,\n",
       "                       -0.0463, -0.0714, -0.1692,  0.2179, -0.0802],\n",
       "                      [-0.1661,  0.0991, -0.1136,  0.0820, -0.0603, -0.1964, -0.1529, -0.1319,\n",
       "                        0.0961, -0.2020, -0.1719,  0.1355, -0.1884,  0.1839,  0.1275, -0.0825,\n",
       "                       -0.1439, -0.0719, -0.1998, -0.1912,  0.1022],\n",
       "                      [-0.1677,  0.1969, -0.0589, -0.0963,  0.0101,  0.0257,  0.0497, -0.1226,\n",
       "                       -0.1346,  0.1341,  0.1540,  0.1812,  0.0978,  0.0139, -0.1652, -0.1280,\n",
       "                        0.0072,  0.1806,  0.1440,  0.1416, -0.1408],\n",
       "                      [-0.0807, -0.0408,  0.0412,  0.1858, -0.0536, -0.0694, -0.0587,  0.0543,\n",
       "                        0.1599, -0.1502,  0.1397, -0.1236,  0.1583, -0.1480,  0.1622, -0.0925,\n",
       "                       -0.0270,  0.1669, -0.0878,  0.0611,  0.1039],\n",
       "                      [-0.0767, -0.1105,  0.1020, -0.1043,  0.0136, -0.0299, -0.0560, -0.1660,\n",
       "                        0.1803,  0.1824, -0.1470,  0.0240,  0.0539,  0.1488, -0.0955,  0.0355,\n",
       "                       -0.0927,  0.0151, -0.0326, -0.0207,  0.1594],\n",
       "                      [-0.0326, -0.1183, -0.0647,  0.1634, -0.0255,  0.1551,  0.0299, -0.1665,\n",
       "                       -0.0142,  0.0354,  0.1428, -0.1006,  0.0977, -0.1572, -0.0018,  0.0524,\n",
       "                       -0.1311,  0.1638,  0.1606, -0.0400,  0.0322]])),\n",
       "             ('layer3.bias',\n",
       "              tensor([-0.1277, -0.0765,  0.1468, -0.0473,  0.1468, -0.0123,  0.0131, -0.1251,\n",
       "                      -0.0251, -0.0466,  0.0042, -0.0074,  0.0666, -0.0971, -0.0212, -0.0852,\n",
       "                       0.0496, -0.0651, -0.0777, -0.0886,  0.1414])),\n",
       "             ('layer4.weight',\n",
       "              tensor([[ 0.0897, -0.1391,  0.1993,  0.2166, -0.1214, -0.0382, -0.0595, -0.1380,\n",
       "                        0.0096, -0.0503, -0.0224, -0.0884, -0.0979,  0.0684,  0.1912, -0.0578,\n",
       "                       -0.1981, -0.2069, -0.1204,  0.0722, -0.1345],\n",
       "                      [-0.2137,  0.0327, -0.0327, -0.0263, -0.0971,  0.1005, -0.0902,  0.2013,\n",
       "                        0.0469, -0.1547, -0.2051, -0.1572, -0.0301,  0.0215, -0.0943, -0.1601,\n",
       "                       -0.1258,  0.2065,  0.1997,  0.2083, -0.1902],\n",
       "                      [-0.1695,  0.0794,  0.0902,  0.0650, -0.1910,  0.0832, -0.1366, -0.0953,\n",
       "                       -0.1322, -0.1106, -0.2006, -0.0756,  0.2010,  0.2087,  0.0905,  0.1932,\n",
       "                        0.0098, -0.0901, -0.0007, -0.1823, -0.1285],\n",
       "                      [ 0.1243, -0.1466,  0.0632, -0.2170, -0.1826, -0.0668, -0.0897,  0.1256,\n",
       "                        0.0738,  0.1862,  0.0487, -0.0009,  0.0879, -0.1061, -0.1859, -0.0227,\n",
       "                        0.0989,  0.0318,  0.0082, -0.1363, -0.1354],\n",
       "                      [ 0.0752,  0.1816, -0.0552, -0.1747, -0.2124, -0.1964,  0.0317, -0.1787,\n",
       "                        0.0182,  0.0595, -0.1481,  0.1628,  0.2161,  0.0755, -0.0934,  0.0729,\n",
       "                        0.0705, -0.1847,  0.2131,  0.0185, -0.0717],\n",
       "                      [ 0.1494,  0.0969,  0.0071, -0.0504, -0.0023,  0.1357,  0.1269, -0.1367,\n",
       "                       -0.1924,  0.1753,  0.0228, -0.0688, -0.0808,  0.2127,  0.1469, -0.0525,\n",
       "                        0.0709,  0.0543,  0.1313,  0.0518,  0.1873],\n",
       "                      [ 0.1970,  0.1378, -0.1187,  0.1643, -0.1135,  0.0278,  0.0624,  0.0746,\n",
       "                        0.1083, -0.0692,  0.0661,  0.2065, -0.0953,  0.0994,  0.0091,  0.2091,\n",
       "                        0.1491, -0.1501, -0.0188,  0.0520, -0.1515],\n",
       "                      [ 0.1759, -0.0705, -0.1057, -0.2058,  0.1947,  0.0946,  0.1104, -0.1910,\n",
       "                        0.0662, -0.2038,  0.1648, -0.0477,  0.2026, -0.0055, -0.1035, -0.1502,\n",
       "                       -0.1575,  0.0585,  0.1216, -0.0408,  0.1415],\n",
       "                      [ 0.2023,  0.2144,  0.0178, -0.1074, -0.1066, -0.1616,  0.1712, -0.1327,\n",
       "                        0.0891, -0.0805,  0.1475,  0.2072, -0.1640, -0.0046,  0.1030,  0.0324,\n",
       "                        0.1499,  0.0187, -0.1135,  0.1869, -0.0239],\n",
       "                      [-0.0469,  0.1664,  0.0331,  0.1369,  0.1529,  0.0936, -0.2147, -0.0436,\n",
       "                       -0.0279,  0.1914, -0.0680, -0.0682, -0.1800, -0.0811, -0.1231, -0.0885,\n",
       "                       -0.0365, -0.0397, -0.1786,  0.0592, -0.1115],\n",
       "                      [ 0.0529,  0.1174, -0.0577,  0.2010,  0.0922,  0.0813,  0.0210, -0.2106,\n",
       "                       -0.0224,  0.0421, -0.0323, -0.2104, -0.0915,  0.0835, -0.1537,  0.0105,\n",
       "                       -0.1734,  0.1221,  0.1641,  0.0743,  0.0967],\n",
       "                      [ 0.1619, -0.1540,  0.1669,  0.1963, -0.0941, -0.0272, -0.1823, -0.1942,\n",
       "                        0.0292, -0.1813, -0.1071, -0.0291, -0.0903, -0.0531,  0.1715,  0.0031,\n",
       "                       -0.2051,  0.1681,  0.1367,  0.0400,  0.1071],\n",
       "                      [-0.0676,  0.1124, -0.1369,  0.1875,  0.1119,  0.0327,  0.0460,  0.1365,\n",
       "                       -0.1479,  0.1686,  0.0958, -0.1831,  0.1141, -0.1700, -0.1011, -0.1359,\n",
       "                       -0.1855,  0.0121,  0.0272, -0.1008, -0.1689],\n",
       "                      [-0.1326,  0.1584, -0.0244,  0.1070,  0.0800,  0.1997, -0.0819, -0.1834,\n",
       "                        0.0847, -0.1160, -0.2015,  0.0950,  0.0795, -0.1421,  0.1762, -0.0629,\n",
       "                        0.0872,  0.1300, -0.0041,  0.0813,  0.1653],\n",
       "                      [ 0.0516,  0.1987,  0.0901, -0.2129,  0.0135, -0.1116,  0.1287,  0.1371,\n",
       "                       -0.1886, -0.1078,  0.2171, -0.1699, -0.1863, -0.0323,  0.0658,  0.1113,\n",
       "                        0.0736,  0.0900,  0.0650,  0.0206, -0.1486],\n",
       "                      [ 0.1130,  0.2043,  0.0035,  0.2055, -0.0218, -0.0550,  0.0848, -0.0295,\n",
       "                       -0.2144,  0.0460,  0.0423, -0.0809,  0.0566, -0.0332,  0.0343,  0.0350,\n",
       "                        0.0677,  0.0064,  0.0187,  0.2120,  0.1670],\n",
       "                      [-0.0818, -0.0952,  0.1753, -0.1624,  0.0026, -0.0162, -0.1932, -0.0032,\n",
       "                        0.1391, -0.0867, -0.0032,  0.1685,  0.1857, -0.0843,  0.1611,  0.1856,\n",
       "                        0.1861,  0.1084,  0.1984,  0.0837,  0.2160],\n",
       "                      [-0.0461, -0.0085,  0.0100, -0.0051,  0.1589, -0.0345, -0.2031, -0.1233,\n",
       "                       -0.1242,  0.0553, -0.2001,  0.0905,  0.1683, -0.0464,  0.0434, -0.1805,\n",
       "                       -0.0788, -0.1283,  0.1395, -0.0675,  0.0108],\n",
       "                      [-0.1014,  0.1103, -0.1832,  0.1664, -0.1290,  0.1793, -0.0590, -0.1249,\n",
       "                       -0.0993, -0.1643,  0.1638,  0.0138,  0.1341,  0.2026, -0.2120, -0.1028,\n",
       "                       -0.0406, -0.0853,  0.1773, -0.2125,  0.0694],\n",
       "                      [ 0.0276, -0.1895, -0.1269, -0.0745,  0.1584, -0.0499, -0.1795,  0.1481,\n",
       "                       -0.2018,  0.1377,  0.1292, -0.0516, -0.1406,  0.1103, -0.1204, -0.1101,\n",
       "                        0.0940, -0.1506,  0.1220,  0.2167,  0.0223],\n",
       "                      [-0.0017,  0.0011, -0.1026, -0.0996,  0.1836, -0.1022,  0.2098,  0.0377,\n",
       "                        0.1418, -0.0846, -0.1480,  0.0665, -0.2012,  0.1731, -0.0732, -0.0696,\n",
       "                        0.0798, -0.1334, -0.0686, -0.1268, -0.0886]])),\n",
       "             ('layer4.bias',\n",
       "              tensor([ 0.1144,  0.0178,  0.1553,  0.1043,  0.0495,  0.0538, -0.0590, -0.0894,\n",
       "                      -0.1272,  0.1270, -0.0060,  0.0376, -0.1119,  0.0538,  0.1735,  0.0603,\n",
       "                      -0.0293,  0.0166,  0.1776, -0.1689, -0.1843])),\n",
       "             ('layer5.weight',\n",
       "              tensor([[ 0.0517, -0.1872, -0.1686,  0.0573,  0.1072, -0.1456,  0.0631,  0.0380,\n",
       "                        0.0819, -0.0532, -0.2126, -0.1674, -0.0404, -0.0548,  0.1334, -0.1744,\n",
       "                        0.1414,  0.1267,  0.2117,  0.0131,  0.0376]])),\n",
       "             ('layer5.bias', tensor([-0.1143]))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function \n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# optimiser function\n",
    "optimiser = torch.optim.SGD(params= model_0.parameters(),\n",
    "                            lr = 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy function\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true,y_pred).sum().item()\n",
    "    acc = correct/len(y_pred) * 100\n",
    "    return acc \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4310],\n",
       "        [-1.2062],\n",
       "        [-1.3000],\n",
       "        [-1.3567],\n",
       "        [-1.4431]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    y_logits = model_0(X_course_test[:5])\n",
    "y_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert the logits to probabilities\n",
    "y_pred_prob = torch.sigmoid(y_logits)\n",
    "y_pred_probs = torch.sigmoid(y_logits).round()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]),\n",
       " tensor([[0.1929],\n",
       "         [0.2304],\n",
       "         [0.2142],\n",
       "         [0.2048],\n",
       "         [0.1911]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_probs, y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_fn(y_course_train[:5],y_pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_course_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7200, 7])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_course_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/5000 [00:00<01:34, 52.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 0.27762, Accuracy: 89.56% | Test loss: 0.30896, Test acc: 87.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 1021/5000 [00:09<00:34, 116.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000 | Loss: 0.28600, Accuracy: 88.89% | Test loss: 0.31683, Test acc: 86.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2023/5000 [00:16<00:22, 131.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 | Loss: 0.26239, Accuracy: 90.69% | Test loss: 0.29999, Test acc: 88.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3019/5000 [00:24<00:14, 135.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3000 | Loss: 0.28435, Accuracy: 88.76% | Test loss: 0.31924, Test acc: 86.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4030/5000 [00:31<00:06, 142.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4000 | Loss: 0.25666, Accuracy: 91.36% | Test loss: 0.29392, Test acc: 89.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:39<00:00, 125.69it/s]\n"
     ]
    }
   ],
   "source": [
    "#creating the training loop \n",
    "\n",
    "epochs = 5000\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    # getting the output from the model, the forward function\n",
    "    y_logits = model_0(X_course_train)\n",
    "    y_pred = torch.round(torch.sigmoid(y_logits))\n",
    "\n",
    "    # calculating the loss \n",
    "    loss = loss_fn(y_logits,y_course_train)\n",
    "    acc = accuracy_fn(y_true= y_course_train,\n",
    "                      y_pred= y_pred)\n",
    "\n",
    "    # setting the optimiser to zero\n",
    "    optimiser.zero_grad()\n",
    "\n",
    "    # applying th loss\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # optimising\n",
    "    optimiser.step()\n",
    "\n",
    "    model_0.eval()\n",
    "    with torch.inference_mode():\n",
    "      # 1. Forward pass\n",
    "      test_logits = model_0(X_course_test)\n",
    "      test_pred = torch.round(torch.sigmoid(test_logits)) # logits -> prediction probabilities -> prediction labels\n",
    "      # 2. Calcuate loss and accuracy\n",
    "      test_loss = loss_fn(test_logits, y_course_test)\n",
    "      test_acc = accuracy_fn(y_true=y_course_test,\n",
    "                             y_pred=test_pred)\n",
    "    if epoch % 1000 == 0:\n",
    "      print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {acc:.2f}% | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model_0(X_course_test[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypre = torch.round(torch.sigmoid(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]], grad_fn=<RoundBackward0>),\n",
       " tensor([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypre, y_course_test[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(42)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eq(ypre,y_course_test[:50]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8400)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eq(ypre,y_course_test[:50]).sum()/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model\n",
    "from pathlib import Path\n",
    "\n",
    "model_path = Path('models')\n",
    "model_path.mkdir(parents= True, exist_ok= True)\n",
    "\n",
    "MODEL_NAME = \"course_completion_prediction_model_0.pth\"\n",
    "MODEL_SAVE_PATH = model_path / MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(obj=model_0.state_dict(), # only saving the state_dict() only saves the models learned parameters\n",
    "           f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model_0 = CourseComp()\n",
    "loaded_model_0.load_state_dict(torch.load(f=MODEL_SAVE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layer1.weight',\n",
       "              tensor([[-2.2757e-01, -1.5209e-01,  4.7703e-02, -2.5512e-01, -3.7636e-01,\n",
       "                       -3.6836e-01, -3.2835e-01],\n",
       "                      [ 6.6830e-03, -2.2669e-01,  9.3980e-01,  4.5961e-01,  4.0215e-01,\n",
       "                       -7.6549e-02, -3.4766e-01],\n",
       "                      [ 2.7516e-01, -1.2290e-01,  8.9792e-03,  2.3954e-01, -1.4666e-01,\n",
       "                        5.1886e-02, -1.0366e-01],\n",
       "                      [-3.2119e-01,  2.1898e-01,  7.2625e-01,  5.2582e-01,  8.0807e-02,\n",
       "                        1.4729e-01, -1.6849e-01],\n",
       "                      [ 3.1271e-01, -1.6324e-01, -9.7296e-02, -7.3685e-02, -3.2474e-01,\n",
       "                        1.5205e-01, -3.5694e-01],\n",
       "                      [-2.5597e-01, -8.5676e-02, -6.0281e-01, -2.4521e-01,  5.2638e-01,\n",
       "                       -1.9588e-01,  2.1613e-01],\n",
       "                      [ 4.0039e-03,  4.1566e-01,  3.2535e-01, -7.8056e-02, -5.8637e-01,\n",
       "                        7.7038e-02,  2.3242e-01],\n",
       "                      [ 8.3421e-02, -5.3882e-02, -6.4884e-01,  1.6323e+00,  1.1113e-01,\n",
       "                        8.3123e-02, -3.4226e-01],\n",
       "                      [-1.1905e-01,  3.0313e-01, -3.2085e-01, -2.0377e-01, -1.0605e-01,\n",
       "                       -2.4527e-01,  2.1838e-01],\n",
       "                      [ 1.4793e-01,  5.2611e-02, -5.8433e-01, -1.8127e+00,  2.4959e-01,\n",
       "                       -1.6996e-01, -1.9101e-01],\n",
       "                      [ 2.0342e-01,  1.4167e-01, -1.1324e+00,  1.2179e-01,  7.5755e-02,\n",
       "                       -6.5106e-02,  2.7496e-01],\n",
       "                      [-7.6807e-02, -2.0036e-01, -8.2843e-01, -2.1137e-01,  3.7940e-01,\n",
       "                       -2.6367e-01, -1.6700e-01],\n",
       "                      [ 3.4943e-01, -1.0800e-01, -3.1005e-01,  8.4998e-02, -1.9816e-01,\n",
       "                       -3.0063e-01,  4.7863e-02],\n",
       "                      [ 4.5085e-01, -1.1630e+00,  2.4708e-01,  1.8764e-01,  2.2033e-01,\n",
       "                        7.8499e-02,  4.1547e-03],\n",
       "                      [ 7.1532e-02, -1.2422e-02, -9.8949e-03,  1.3647e+00, -2.7950e-02,\n",
       "                       -7.6595e-03,  8.8529e-02],\n",
       "                      [-4.2112e-01,  1.5104e-01,  3.3757e-01,  3.6339e-01,  9.1778e-02,\n",
       "                       -3.6313e-01,  9.3744e-02],\n",
       "                      [ 6.4413e-02, -3.4600e-01,  1.6098e-01, -3.5644e-01, -1.5073e-01,\n",
       "                       -3.3222e-02, -1.0730e-01],\n",
       "                      [-2.0871e-01,  1.8217e-01, -8.6563e-02,  1.9561e-03, -3.3141e-01,\n",
       "                        2.0227e-02, -1.2595e-01],\n",
       "                      [-3.4181e-01,  2.9895e-01, -4.9989e-01, -4.8340e-01, -1.8600e-01,\n",
       "                       -5.5660e-02,  6.3848e-02],\n",
       "                      [-1.4757e-01, -1.4485e-03, -3.4847e-01, -6.5330e-01, -1.5062e-01,\n",
       "                        4.4067e-01, -1.1361e-01],\n",
       "                      [ 2.5462e-01,  5.8100e-02,  3.6490e-01,  1.8346e-01, -3.0865e-01,\n",
       "                        1.4982e-01,  3.1219e-01]])),\n",
       "             ('layer1.bias',\n",
       "              tensor([-0.1778, -0.4234,  0.0366, -0.6041,  0.0078, -0.5683,  0.1379,  0.2545,\n",
       "                      -0.3558,  0.2997, -0.1125,  0.2584,  0.1697, -0.0845, -0.3413,  0.0187,\n",
       "                      -0.0700, -0.1122, -0.3068, -0.3733, -0.0285])),\n",
       "             ('layer2.weight',\n",
       "              tensor([[ 0.1829,  0.1872,  0.0987,  0.1610,  0.0528, -0.2624, -0.3332,  0.2389,\n",
       "                       -0.1343, -0.2581, -0.0398, -0.3058,  0.1980, -0.3634, -0.0353,  0.0968,\n",
       "                        0.1411,  0.0828,  0.1795,  0.2433, -0.0441],\n",
       "                      [ 0.1114, -0.2201, -0.1076,  0.0282, -0.2162, -0.1959,  0.2203,  0.0016,\n",
       "                        0.1266,  0.1338,  0.0121, -0.1595, -0.1072,  0.0600,  0.2405,  0.0890,\n",
       "                        0.0761, -0.1436,  0.1160,  0.0956,  0.0488],\n",
       "                      [-0.0813, -0.4896, -0.2105, -0.3830, -0.0710,  0.4991, -0.0778,  0.6031,\n",
       "                        0.0687,  0.0131,  0.6156, -0.0207, -0.1657,  0.4373, -0.0280, -0.2184,\n",
       "                       -0.1980,  0.0584, -0.0743,  0.3219, -0.0255],\n",
       "                      [ 0.0767,  0.2769, -0.0321, -0.0378,  0.1165,  0.0077, -0.0929,  0.0620,\n",
       "                       -0.2265,  0.1657,  0.2077, -0.3564,  0.1363, -0.3377,  0.0309,  0.0254,\n",
       "                       -0.0465,  0.2067, -0.1325,  0.0025, -0.0294],\n",
       "                      [-0.0181, -0.1602, -0.1946,  0.0653,  0.1164,  0.1174, -0.1985,  0.0337,\n",
       "                       -0.0491,  0.2542, -0.1447,  0.1690,  0.0301, -0.0087,  0.2941, -0.2362,\n",
       "                       -0.1014,  0.1222, -0.2049,  0.2712,  0.0070],\n",
       "                      [-0.1407, -0.0208, -0.1717, -0.0031,  0.2141, -0.1969, -0.0687, -0.4518,\n",
       "                       -0.1144, -0.1658, -0.1423, -0.1990, -0.0098, -0.0681, -0.5485,  0.1007,\n",
       "                       -0.0946, -0.1481,  0.1747,  0.3377,  0.0026],\n",
       "                      [-0.0385,  0.0486, -0.0180,  0.1448, -0.1457, -0.2720,  0.1840, -0.2793,\n",
       "                       -0.2592,  0.8296, -0.2925, -0.0422,  0.0639, -0.1375, -0.3304,  0.0663,\n",
       "                       -0.0260, -0.1589,  0.1355, -0.4493,  0.1268],\n",
       "                      [ 0.0230, -0.0507, -0.1636, -0.1895, -0.0175, -0.2289, -0.1208,  0.1590,\n",
       "                        0.0091,  0.1567,  0.0716,  0.1039,  0.0517, -0.1835, -0.1433,  0.0238,\n",
       "                        0.0891, -0.0421,  0.1078,  0.0132, -0.2087],\n",
       "                      [-0.1873,  0.2021, -0.0353, -0.0443,  0.1656, -0.0586, -0.2351,  0.1991,\n",
       "                        0.2148,  0.0893,  0.0010, -0.0531, -0.1062, -0.3483, -0.1252,  0.2788,\n",
       "                       -0.1684,  0.0980,  0.1318, -0.0601,  0.0048],\n",
       "                      [-0.1220, -0.0257,  0.1583,  0.0371, -0.0837,  0.4924,  0.0276, -0.5675,\n",
       "                       -0.0682,  0.2941, -0.2073,  0.0184,  0.0539,  0.1816, -0.0655, -0.0279,\n",
       "                       -0.1978,  0.0134, -0.0648,  0.1029, -0.3089],\n",
       "                      [-0.0337, -0.2500, -0.0093,  0.0046, -0.1869, -0.2452,  0.0992,  0.1374,\n",
       "                       -0.0591, -0.1984, -0.0936,  0.0089, -0.0385, -0.1661, -0.2470,  0.1499,\n",
       "                        0.1609, -0.0865, -0.1616,  0.1190,  0.1797],\n",
       "                      [ 0.0600,  0.2749, -0.1845, -0.1233,  0.1352, -0.0011, -0.1825, -0.1553,\n",
       "                        0.1427,  0.1392,  0.2685, -0.0173,  0.0509,  0.4469, -0.0811, -0.0053,\n",
       "                       -0.1560,  0.0765,  0.1097, -0.2355, -0.2370],\n",
       "                      [-0.0854,  0.0045, -0.0855,  0.0896, -0.1271,  0.0881,  0.0023,  0.4086,\n",
       "                        0.1850, -0.1218,  0.0984, -0.0030, -0.0880, -0.1383,  0.2797, -0.2595,\n",
       "                        0.1885,  0.2015, -0.2111, -0.3837,  0.1859],\n",
       "                      [-0.0507,  0.2737, -0.1221, -0.3030,  0.0314, -0.2739, -0.0818,  0.0272,\n",
       "                       -0.0291, -0.0933, -0.3079,  0.2387,  0.0582,  0.4912,  0.0895,  0.2637,\n",
       "                       -0.0628,  0.2037, -0.2057,  0.1425, -0.0846],\n",
       "                      [ 0.0951,  0.0176, -0.1903,  0.1170,  0.0542, -0.1217, -0.1646, -0.2739,\n",
       "                       -0.1821,  0.1102,  0.0623, -0.1789, -0.0436,  0.0140, -0.1279, -0.3379,\n",
       "                        0.2045, -0.1194, -0.0427, -0.0642, -0.0479],\n",
       "                      [ 0.0870, -0.0781,  0.1697, -0.1087, -0.1313,  0.0915,  0.1651,  0.2952,\n",
       "                        0.0647,  0.3927,  0.1531, -0.0322, -0.1064,  0.2582,  0.1891, -0.0618,\n",
       "                       -0.0864,  0.0345, -0.1093,  0.1337, -0.0746],\n",
       "                      [ 0.1311, -0.0664,  0.0075,  0.1207,  0.1966,  0.2599,  0.2337, -0.1668,\n",
       "                       -0.0193,  0.1532, -0.0847,  0.0763,  0.1190, -0.0207, -0.1240,  0.0030,\n",
       "                       -0.1062, -0.0336,  0.0462, -0.4624,  0.1372],\n",
       "                      [ 0.0143,  0.0315, -0.1168,  0.1928, -0.1522,  0.3261, -0.0342, -0.1470,\n",
       "                       -0.0625, -0.4669,  0.0983,  0.0530,  0.0400, -0.3040, -0.3142, -0.3611,\n",
       "                       -0.0102, -0.0729, -0.0256,  0.2302, -0.0602],\n",
       "                      [ 0.2031, -0.0652,  0.1802, -0.1359, -0.1499,  0.1487, -0.0639,  0.0614,\n",
       "                        0.0395,  0.0335, -0.1047, -0.1756,  0.0816, -0.0974,  0.0764,  0.0321,\n",
       "                       -0.0730, -0.0095,  0.0629, -0.1264,  0.1425],\n",
       "                      [-0.1210, -0.0393, -0.1219,  0.1445, -0.1630,  0.2371, -0.1669, -0.1714,\n",
       "                       -0.1298, -0.3804, -0.2968,  0.0814,  0.0935, -0.1895,  0.1752,  0.2199,\n",
       "                        0.1768, -0.0893, -0.2450, -0.3355,  0.2091],\n",
       "                      [ 0.0254, -0.2612, -0.0488,  0.2046, -0.1659, -0.2590,  0.0414, -0.1854,\n",
       "                       -0.2196,  0.3415, -0.0754,  0.1804, -0.0944,  0.0205,  0.0920, -0.3059,\n",
       "                       -0.1509,  0.0037, -0.1092,  0.0390,  0.2145]])),\n",
       "             ('layer2.bias',\n",
       "              tensor([-0.6784, -0.0451,  0.2300,  0.0532,  0.0957, -0.1259,  0.1901,  0.0883,\n",
       "                      -0.3293, -0.0082, -0.1455, -0.0725, -0.2886,  0.0934, -0.2141, -0.1801,\n",
       "                       0.2144, -0.7600,  0.1452,  0.0579, -0.2224])),\n",
       "             ('layer3.weight',\n",
       "              tensor([[ 3.3950e-01,  4.1119e-02, -3.1867e-01, -2.1195e-01,  1.6426e-01,\n",
       "                       -2.7656e-01,  4.2982e-02, -1.8837e-01, -2.5021e-01, -8.8746e-02,\n",
       "                       -2.5806e-01, -5.5103e-02, -2.4224e-01, -1.9865e-01, -1.3624e-01,\n",
       "                        1.2886e-01,  1.5371e-01,  1.9795e-01,  1.5623e-01,  8.5891e-02,\n",
       "                        6.4817e-03],\n",
       "                      [ 6.8452e-02, -1.6170e-01,  5.4268e-02,  1.1749e-01, -2.6582e-01,\n",
       "                        7.4748e-02,  9.2618e-03, -1.7660e-01, -1.2221e-01, -1.6881e-01,\n",
       "                       -2.5264e-01,  2.3782e-01,  2.2143e-01,  2.2868e-01, -2.1176e-02,\n",
       "                        1.7147e-02, -2.7392e-02,  8.8672e-02,  2.0824e-01,  5.3290e-02,\n",
       "                        6.4817e-02],\n",
       "                      [-3.1805e-03,  1.4039e-01, -4.0150e-02, -3.5641e-02,  1.4747e-01,\n",
       "                        2.6681e-01, -1.6484e-01, -1.4479e-01,  6.7270e-02, -2.1422e-01,\n",
       "                        1.5898e-01, -2.0357e-01, -1.6457e-01,  2.2503e-01,  2.9415e-02,\n",
       "                        2.8816e-01, -1.3543e-01, -8.3040e-02,  3.4903e-02, -2.9190e-02,\n",
       "                        1.5779e-02],\n",
       "                      [ 1.9452e-01, -4.4472e-02,  1.1032e-01, -1.6976e-01, -4.3986e-02,\n",
       "                        2.8032e-01,  2.0131e-01, -1.6728e-01,  1.4962e-02,  1.2695e-02,\n",
       "                        2.6785e-02,  1.7471e-02, -4.2932e-01,  8.9864e-02,  6.3098e-03,\n",
       "                        7.2712e-02, -2.9375e-01,  1.2022e-02,  7.8542e-02,  3.5833e-03,\n",
       "                       -7.8741e-03],\n",
       "                      [-2.0419e-01,  1.1102e-01,  1.4656e-01,  1.8297e-01,  8.6962e-03,\n",
       "                        1.3482e-01, -2.3778e-02,  1.1197e-01,  9.2477e-03, -4.8534e-01,\n",
       "                        1.0961e-01,  1.1467e-01,  1.7967e-01,  9.2275e-02,  2.0380e-01,\n",
       "                       -6.9763e-02, -3.6574e-02, -2.3536e-01, -6.8393e-02,  3.3403e-01,\n",
       "                       -1.6562e-01],\n",
       "                      [-1.1729e-01, -1.5587e-01,  6.5310e-02,  2.3295e-01, -2.4140e-01,\n",
       "                        2.7579e-01,  1.3838e-01, -6.1747e-02, -1.8530e-01,  3.5308e-01,\n",
       "                        1.6815e-01, -2.3271e-01, -4.2067e-01, -6.1772e-02, -8.1663e-02,\n",
       "                       -3.6276e-01, -1.2750e-01,  4.2945e-01,  1.6801e-01,  2.2082e-01,\n",
       "                       -1.9733e-01],\n",
       "                      [-1.6501e-01, -9.6084e-02, -1.9699e-02,  4.8641e-02, -2.4007e-01,\n",
       "                        1.8257e-01, -1.3740e-01,  1.3847e-03,  2.2663e-01, -2.7926e-01,\n",
       "                        1.6801e-01, -1.4030e-01, -2.6344e-03, -1.9805e-01, -1.4641e-01,\n",
       "                        1.2142e-01,  1.8261e-01, -6.0843e-02,  5.9702e-02,  3.5629e-01,\n",
       "                        3.6679e-02],\n",
       "                      [ 4.1644e-02,  1.3113e-01,  2.8961e-01,  2.2669e-01,  1.5341e-01,\n",
       "                        1.0758e-01,  2.9050e-01, -5.5383e-02, -2.0371e-01,  1.4878e-01,\n",
       "                       -2.7625e-01,  3.2794e-01, -1.3803e-01,  4.2276e-03, -1.1367e-01,\n",
       "                        2.2679e-01, -3.4597e-01,  7.8370e-02,  7.7077e-02, -3.2991e-01,\n",
       "                       -4.2206e-02],\n",
       "                      [-3.2450e-01, -2.6436e-02,  1.2664e-01, -9.9845e-02, -1.8146e-02,\n",
       "                       -1.2594e-01, -1.5716e-01,  1.3993e-02, -1.9698e-02, -2.3701e-01,\n",
       "                        9.2081e-02,  3.1233e-01,  2.8764e-01,  3.1779e-01,  1.4899e-01,\n",
       "                       -2.6354e-02,  1.1781e-03,  3.0900e-01, -5.2121e-02,  3.2952e-01,\n",
       "                        2.1152e-01],\n",
       "                      [-1.6832e-01, -6.0570e-02,  2.1937e-01, -1.3318e-01,  2.9213e-01,\n",
       "                       -8.1533e-04, -2.6464e-01,  3.3574e-03, -2.1296e-01, -3.0435e-02,\n",
       "                       -2.1153e-02, -3.3900e-01,  1.0188e-01, -2.6027e-01,  6.0567e-02,\n",
       "                        3.5351e-01,  2.0148e-01, -1.2750e-01,  1.1127e-01,  1.0878e-02,\n",
       "                       -2.3853e-01],\n",
       "                      [ 3.5094e-02, -7.5529e-02,  8.6320e-02, -1.0783e-01, -2.4402e-02,\n",
       "                       -1.0271e-01, -2.1177e-01, -1.0734e-01,  3.9289e-02,  2.1259e-01,\n",
       "                       -2.4136e-02,  8.3459e-02,  2.5376e-01, -1.8287e-01,  8.0815e-02,\n",
       "                        2.2216e-01, -7.4030e-03,  8.7973e-03,  1.8295e-01,  3.4904e-03,\n",
       "                        1.6561e-01],\n",
       "                      [ 7.5225e-02,  2.9213e-01, -3.1955e-02, -1.3132e-01, -1.7354e-01,\n",
       "                       -9.3004e-02,  1.8452e-01,  6.6343e-02, -4.7499e-02,  2.5096e-02,\n",
       "                       -1.4180e-01, -4.6538e-02, -2.2406e-01, -1.6776e-01, -1.9837e-01,\n",
       "                        3.7484e-02,  1.0012e-01, -6.2231e-02, -1.9413e-01, -2.0185e-01,\n",
       "                        3.8566e-02],\n",
       "                      [ 1.8704e-01,  1.1690e-01, -8.2015e-01,  2.3204e-01,  1.1591e-02,\n",
       "                       -3.5092e-01, -2.3754e-01,  1.1495e-01,  6.5184e-02,  2.8221e-01,\n",
       "                        5.1307e-02, -1.5980e-01,  8.1524e-02, -5.6654e-01,  2.2330e-01,\n",
       "                       -3.2498e-01, -3.3956e-02, -2.7339e-02, -5.9680e-02,  1.9522e-01,\n",
       "                        2.3591e-01],\n",
       "                      [-6.6710e-02,  1.0840e-01, -3.8848e-01, -6.5342e-02,  2.0713e-01,\n",
       "                        7.4666e-02, -2.2118e-02,  9.2664e-02, -1.4248e-01,  2.8693e-01,\n",
       "                        2.5076e-03, -1.2580e-01,  3.5705e-02, -2.0294e-02,  1.3395e-01,\n",
       "                       -1.1181e-01,  2.6279e-01,  8.6965e-02,  4.5001e-02,  2.3852e-01,\n",
       "                        1.5343e-01],\n",
       "                      [ 9.1850e-03,  2.0182e-01,  5.0316e-02, -4.5648e-02, -3.6580e-02,\n",
       "                        2.0922e-01,  7.4148e-02, -8.8801e-02, -1.2655e-02,  5.9861e-03,\n",
       "                       -4.6252e-02, -1.2444e-01, -2.6494e-01,  1.5563e-01, -1.8558e-01,\n",
       "                        1.6980e-01,  9.9149e-02, -1.3658e-01,  1.5849e-01, -1.5776e-01,\n",
       "                        2.4019e-01],\n",
       "                      [-2.8928e-01, -1.9398e-01, -1.8566e-01, -1.0701e-01, -1.4979e-01,\n",
       "                       -2.9046e-02, -1.1510e-01, -1.9819e-01,  2.0300e-01, -1.0217e-01,\n",
       "                        2.1036e-01,  1.2665e-01, -4.7552e-02, -3.1965e-01,  4.0352e-02,\n",
       "                        6.9014e-02,  7.8777e-03, -1.1056e-01, -1.6905e-01,  1.9601e-01,\n",
       "                       -8.0171e-02],\n",
       "                      [-2.5911e-01,  9.9120e-02, -1.0953e-01,  1.1511e-01, -8.0652e-02,\n",
       "                       -1.9640e-01, -1.5301e-01, -1.3194e-01,  1.5377e-01, -1.8875e-01,\n",
       "                       -1.7187e-01,  1.3767e-01, -9.2578e-02,  1.1658e-01,  1.2495e-01,\n",
       "                       -1.1882e-01, -1.2302e-01, -4.6441e-02, -1.9976e-01, -1.4100e-01,\n",
       "                        1.0220e-01],\n",
       "                      [-2.9891e-01,  2.3659e-01,  8.0779e-02, -3.6234e-01, -2.2878e-01,\n",
       "                        8.1724e-02,  1.8917e-01, -1.2354e-01, -2.9458e-01,  1.2095e-01,\n",
       "                        1.2557e-01,  3.9634e-01,  2.7881e-01,  7.1442e-02, -3.0603e-01,\n",
       "                       -2.3174e-01,  8.2919e-02,  3.6196e-01,  1.4416e-01,  6.4108e-02,\n",
       "                       -1.8386e-01],\n",
       "                      [-1.3156e-02, -1.8869e-02,  6.4813e-02,  9.2979e-02, -1.6873e-02,\n",
       "                       -1.5053e-01, -2.5462e-01,  4.9913e-02,  2.1927e-01, -2.1005e-01,\n",
       "                        7.5814e-02,  1.2339e-01,  1.2351e-01, -9.1855e-02,  1.8126e-01,\n",
       "                        1.3168e-01, -2.2278e-01,  2.1515e-01, -8.7777e-02, -1.2214e-01,\n",
       "                        1.4903e-01],\n",
       "                      [-2.2755e-01, -1.2748e-01,  2.0586e-01, -3.6583e-01,  5.8170e-02,\n",
       "                       -5.3043e-02,  4.9638e-02, -1.5621e-01,  1.6539e-01,  2.8768e-01,\n",
       "                       -1.6147e-01, -1.4435e-01, -1.0857e-01,  1.7089e-01, -1.3076e-01,\n",
       "                        5.8098e-02, -4.3129e-02,  2.0686e-01, -3.2513e-02, -7.6996e-02,\n",
       "                        8.7556e-02],\n",
       "                      [-1.2247e-01, -1.1358e-01, -1.2067e-01,  1.8412e-01, -1.7428e-01,\n",
       "                        1.9150e-01, -1.0194e-02, -1.6542e-01, -4.3011e-02, -2.0266e-02,\n",
       "                        1.4627e-01, -1.3910e-01,  6.6314e-02, -9.5824e-02,  1.3592e-02,\n",
       "                       -4.7415e-02, -1.4311e-01,  6.4936e-02,  1.6061e-01,  5.3310e-02,\n",
       "                        9.7362e-02]])),\n",
       "             ('layer3.bias',\n",
       "              tensor([-0.3165, -0.2175,  0.2384,  0.0691,  0.9699,  0.3929, -0.1282, -0.5012,\n",
       "                      -0.5069,  0.2471, -0.6083,  0.0146, -0.8310, -0.2960, -0.0102, -0.1185,\n",
       "                       0.0441,  0.1917, -0.8897,  0.0287,  0.3879])),\n",
       "             ('layer4.weight',\n",
       "              tensor([[ 5.9756e-02, -1.4525e-01,  1.9367e-01,  2.0446e-01, -1.2147e-01,\n",
       "                       -5.5363e-02, -5.9744e-02, -1.5199e-01,  1.4651e-02, -5.2588e-02,\n",
       "                       -2.6006e-02, -8.7272e-02, -1.0452e-01,  6.1575e-02,  1.9167e-01,\n",
       "                       -5.7863e-02, -1.9807e-01, -2.0865e-01, -1.3573e-01,  8.0016e-02,\n",
       "                       -1.3571e-01],\n",
       "                      [-1.2486e-01, -4.9202e-03,  4.9388e-02,  3.5134e-02, -1.3404e-01,\n",
       "                        2.4076e-01, -1.5548e-01,  1.2362e-01,  7.8817e-02, -1.2717e-01,\n",
       "                       -1.5907e-01, -1.7267e-01, -1.5822e-01, -4.7048e-02, -1.1570e-01,\n",
       "                       -1.5498e-01, -1.1714e-01,  2.9348e-01,  2.4374e-01,  2.4954e-01,\n",
       "                       -1.7560e-01],\n",
       "                      [-2.8440e-01,  2.5056e-01,  1.2742e-01,  1.5323e-01, -4.2215e-02,\n",
       "                       -8.7004e-02, -1.8218e-01, -1.4283e-01, -1.6713e-01, -7.5156e-02,\n",
       "                       -3.3550e-01, -9.3913e-02,  2.8512e-01,  1.6838e-01,  1.0862e-01,\n",
       "                        1.7146e-01,  2.6584e-02, -3.7840e-02, -5.8637e-02, -2.4082e-01,\n",
       "                       -5.9368e-02],\n",
       "                      [ 1.1781e-01, -1.6396e-01,  5.5984e-02, -2.1732e-01, -1.8724e-01,\n",
       "                       -8.9192e-02, -9.0037e-02,  1.1495e-01,  4.3102e-02,  1.7684e-01,\n",
       "                        2.7442e-04,  1.2119e-03,  8.3126e-02, -1.0417e-01, -1.8401e-01,\n",
       "                       -2.3786e-02,  9.8852e-02,  1.1633e-02, -3.0715e-02, -1.5456e-01,\n",
       "                       -1.3457e-01],\n",
       "                      [ 1.0700e-01,  2.5680e-01, -1.5595e-01, -2.1860e-01, -4.7517e-01,\n",
       "                       -4.5675e-01,  1.8177e-01,  1.2423e-01,  5.9425e-02, -8.3580e-02,\n",
       "                       -9.5402e-02,  2.0549e-01,  3.1070e-01,  2.2346e-01, -9.7159e-02,\n",
       "                        2.0874e-01,  7.2543e-02, -1.4558e-01,  2.2239e-01, -3.4096e-02,\n",
       "                       -1.1876e-01],\n",
       "                      [ 1.6699e-01,  1.9051e-01,  9.3022e-02, -7.4851e-02,  7.4133e-02,\n",
       "                        5.0609e-02,  5.3089e-02, -1.6272e-01, -1.8217e-01,  1.9044e-01,\n",
       "                        4.3855e-02, -1.0738e-01, -1.3011e-01,  2.5096e-02,  1.2715e-01,\n",
       "                       -1.0990e-01,  8.0935e-02,  7.3420e-03,  2.0477e-01, -2.6152e-03,\n",
       "                        2.1803e-01],\n",
       "                      [ 1.3352e-01,  2.9730e-01, -2.0788e-01,  1.5837e-01, -1.0097e-01,\n",
       "                       -3.4556e-02,  1.2549e-01,  1.1685e-01,  1.9224e-01, -1.9443e-01,\n",
       "                       -1.6092e-02,  2.3853e-01,  2.3755e-05,  1.4232e-01,  4.5288e-02,\n",
       "                        2.8304e-01,  1.3947e-01, -2.9505e-01, -1.4019e-02, -1.0870e-01,\n",
       "                       -1.6959e-01],\n",
       "                      [ 3.1901e-01, -1.3161e-01, -9.6695e-02, -2.5488e-01, -1.3084e-02,\n",
       "                        2.9012e-01,  1.4063e-01, -1.5434e-01, -6.5868e-02, -3.3047e-01,\n",
       "                        9.0138e-02, -4.0981e-02,  1.8684e-01,  2.6230e-02, -1.2450e-01,\n",
       "                       -9.9072e-02, -1.5747e-01, -1.2289e-02,  2.3845e-02, -1.5066e-01,\n",
       "                        1.0473e-01],\n",
       "                      [ 2.3135e-01,  4.6982e-01, -4.4974e-02, -6.0641e-02, -1.0221e-01,\n",
       "                       -3.0881e-01,  2.3498e-01, -3.2250e-02,  2.0026e-01, -7.4149e-02,\n",
       "                        1.2964e-01,  2.4409e-01, -9.0147e-02,  2.9810e-02,  1.2381e-01,\n",
       "                        6.6987e-02,  1.4004e-01, -1.4060e-02, -1.4591e-02,  1.6443e-01,\n",
       "                       -3.3460e-02],\n",
       "                      [-3.6154e-02,  1.6171e-01,  1.5762e-01,  2.0024e-01,  2.7270e-01,\n",
       "                        1.4325e-01, -2.1591e-01, -1.8255e-01, -3.5406e-02,  2.3956e-01,\n",
       "                        3.7786e-02, -9.7291e-02, -2.1648e-01, -5.8864e-02, -1.7478e-01,\n",
       "                       -9.7194e-02, -2.2190e-02,  1.5931e-01, -1.6069e-01,  1.0661e-01,\n",
       "                       -2.1827e-02],\n",
       "                      [-5.4340e-02,  1.3348e-01,  6.9451e-02,  2.5346e-01,  1.9053e-01,\n",
       "                        1.2215e-01, -5.0730e-02, -2.1245e-01, -1.3254e-01,  1.5222e-01,\n",
       "                       -2.0064e-02, -2.6417e-01, -2.6007e-01,  2.7092e-02, -2.1471e-01,\n",
       "                       -5.6515e-02, -1.6417e-01,  2.3447e-01,  7.0593e-03,  1.0721e-01,\n",
       "                        1.3867e-01],\n",
       "                      [ 1.4802e-01, -1.7132e-01,  1.9069e-01,  2.2646e-01, -9.5211e-02,\n",
       "                       -5.1254e-02, -1.8336e-01, -1.6312e-01,  1.6793e-02, -1.4869e-01,\n",
       "                       -1.2907e-01, -3.7951e-02, -1.4977e-01, -8.8471e-02,  1.7301e-01,\n",
       "                        2.7040e-03, -2.0505e-01,  1.2960e-01,  1.2527e-01,  1.8160e-02,\n",
       "                        1.0560e-01],\n",
       "                      [-1.1362e-01,  1.2312e-01, -1.4841e-01,  1.9783e-01,  1.3079e-01,\n",
       "                        5.8206e-02,  5.4940e-02,  9.0872e-02, -1.1199e-01,  1.5731e-01,\n",
       "                        3.6949e-02, -1.8185e-01,  9.9452e-02, -1.5991e-01, -9.5655e-02,\n",
       "                       -1.2708e-01, -1.8834e-01,  5.6826e-03, -2.4949e-02, -1.3210e-01,\n",
       "                       -1.7456e-01],\n",
       "                      [-1.9461e-01,  1.7936e-01,  3.1232e-02,  1.8063e-01,  1.0186e-01,\n",
       "                        1.0142e-01, -1.5919e-01, -2.7612e-01,  6.3894e-02, -2.0342e-03,\n",
       "                       -2.4337e-01,  7.8406e-02,  1.2418e-01, -1.0851e-01,  1.9225e-01,\n",
       "                       -1.4101e-01,  9.5076e-02,  8.4685e-02,  1.7475e-02,  3.8532e-02,\n",
       "                        2.1807e-01],\n",
       "                      [ 4.3633e-02,  2.3890e-01,  7.1236e-02, -2.0742e-01,  1.1433e-02,\n",
       "                       -2.4663e-01,  1.6656e-01,  1.9143e-01, -1.2518e-01, -1.3817e-01,\n",
       "                        1.9802e-01, -1.4923e-01, -1.5916e-01,  1.6792e-02,  8.8979e-02,\n",
       "                        1.2784e-01,  7.0127e-02,  7.2494e-02,  6.9622e-02,  2.3159e-03,\n",
       "                       -1.6616e-01],\n",
       "                      [-4.3282e-02,  1.4492e-01, -3.1585e-02,  1.8868e-01,  8.6627e-04,\n",
       "                       -1.1266e-01,  9.9955e-02,  1.6877e-02, -2.4796e-01,  5.4955e-02,\n",
       "                        4.1288e-02, -9.0402e-02,  5.4206e-02, -1.6264e-01,  4.6605e-03,\n",
       "                        2.0184e-02,  8.6136e-02,  6.1662e-02, -7.8175e-02,  2.5107e-01,\n",
       "                        2.5165e-01],\n",
       "                      [-5.0157e-02, -7.8212e-02,  1.4548e-01, -1.0084e-01, -6.1157e-02,\n",
       "                       -9.2475e-02, -1.1266e-01,  2.0274e-01,  1.5472e-01, -1.6368e-01,\n",
       "                       -8.2794e-02,  2.0457e-01,  2.1461e-01,  3.6583e-02,  1.8900e-01,\n",
       "                        2.4648e-01,  1.7608e-01,  9.6324e-02,  1.7024e-01,  1.0084e-01,\n",
       "                        1.9077e-01],\n",
       "                      [-2.5945e-04,  4.1543e-02, -6.2984e-02, -3.0395e-02,  1.7435e-01,\n",
       "                       -5.0099e-03, -2.0472e-01, -6.5230e-02, -7.5860e-02,  9.9042e-02,\n",
       "                       -8.6569e-02,  9.2039e-02,  1.4605e-01, -4.7954e-02,  2.5841e-02,\n",
       "                       -1.5889e-01, -7.2772e-02, -2.1722e-01,  2.9613e-01, -8.4219e-02,\n",
       "                        2.8381e-03],\n",
       "                      [-4.3227e-02,  2.3599e-01, -2.0731e-01,  9.6231e-02, -2.6467e-01,\n",
       "                        1.5629e-01,  5.1624e-02,  5.0896e-02, -1.6295e-02, -1.7685e-01,\n",
       "                        1.5994e-01,  1.3462e-02,  1.9367e-01,  2.2702e-01, -2.2909e-01,\n",
       "                       -1.2031e-02, -3.8101e-02, -2.7335e-01,  1.9223e-01, -4.1842e-01,\n",
       "                        4.0166e-02],\n",
       "                      [ 2.8244e-03,  1.7941e-02, -1.2423e-01, -1.8554e-02,  2.7513e-01,\n",
       "                       -3.8119e-02, -1.3785e-01,  2.4417e-01, -1.5581e-01,  1.3968e-01,\n",
       "                        1.1571e-01, -5.0842e-02, -2.6633e-02,  1.6029e-01, -1.0782e-01,\n",
       "                       -1.1099e-01,  9.8506e-02, -2.1865e-01,  1.8744e-01,  1.9525e-01,\n",
       "                        3.7136e-02],\n",
       "                      [-6.8230e-03,  3.5900e-02, -1.0520e-01, -1.0365e-01,  2.0950e-01,\n",
       "                       -1.1387e-01,  2.0406e-01,  5.1813e-02,  1.6460e-01, -9.4412e-02,\n",
       "                       -1.4960e-01,  6.9011e-02, -2.0857e-01,  1.5522e-01, -7.4554e-02,\n",
       "                       -6.9270e-02,  7.8742e-02, -9.6960e-02, -7.5267e-02, -1.2571e-01,\n",
       "                       -8.9451e-02]])),\n",
       "             ('layer4.bias',\n",
       "              tensor([ 0.1107,  0.3594,  0.5769,  0.0877, -0.8179,  0.6412, -0.6022, -0.4743,\n",
       "                      -0.5381,  1.0862,  0.9820,  0.0259, -0.2013,  0.4884, -0.1036,  0.6296,\n",
       "                      -0.6106, -0.4158, -0.5748, -0.3264, -0.1942])),\n",
       "             ('layer5.weight',\n",
       "              tensor([[ 0.0683, -0.4407, -0.7158, -0.0103,  0.9773, -0.5483,  0.6806,  0.5646,\n",
       "                        0.6497, -0.9939, -0.9420, -0.1975,  0.1584, -0.5363,  0.2233, -0.6140,\n",
       "                        0.5350,  0.4418,  0.6674,  0.3190,  0.1356]])),\n",
       "             ('layer5.bias', tensor([-1.7371]))])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asp_ner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
